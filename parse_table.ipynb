{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "parse_table.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-_-cjy38MFZr"
      },
      "outputs": [],
      "source": [
        "import pandas\n",
        "import numpy\n",
        "import torch\n",
        "\n",
        "metallicity_table = {\"[m/H]\":1, \"[M/H]\":1, \"[Fe/H]\":2}\n",
        "def metallicity_parser(input_string):\n",
        "  return metallicity_table.get(input_string, numpy.nan)\n",
        "\n",
        "def average_or_nan(series, default=numpy.nan):\n",
        "  if (pandas.isna(series) != True).any():\n",
        "    return series.mean()\n",
        "  else:\n",
        "    return default\n",
        "\n",
        "def max_or_nan(series):\n",
        "  if (pandas.isna(series) != True).any():\n",
        "    return series.max()\n",
        "  else:\n",
        "    return numpy.nan\n",
        "\n",
        "def find_metallicity_standard(series):\n",
        "  uses_M_H = (series == 1)\n",
        "  if uses_M_H.any():\n",
        "    return 1, uses_M_H\n",
        "  else:\n",
        "    uses_Fe_H = (series == 2)\n",
        "    if uses_Fe_H.any():\n",
        "      return 2, uses_Fe_H\n",
        "    else:\n",
        "      return numpy.nan, uses_Fe_H\n",
        "\n",
        "def parse_table(file_path, existing_stars, available_series):\n",
        "  \"\"\"\n",
        "  Inputs:\n",
        "    file_path: String.\n",
        "    existing_stars: Set. Contains strings.\n",
        "  Outputs:\n",
        "    model_x1: 3D PyTorch tensor.\n",
        "    model_x1_mask: 2D PyTorch tensor.\n",
        "    model_y: 3D PyTorch tensor.\n",
        "  \"\"\"\n",
        "\n",
        "  triplet_data = {(\"sy_pm\", \"sy_pmerr1\", \"sy_pmerr2\"), (\"sy_dist\", \"sy_disterr1\", \"sy_disterr2\")}\n",
        "  quadruplet_data = {(\"st_mass\", \"st_masserr1\", \"st_masserr2\", \"st_masslim\"), (\"st_met\", \"st_meterr1\", \"st_meterr2\", \"st_metlim\"),\n",
        "                     (\"st_age\", \"st_ageerr1\", \"st_ageerr2\", \"st_agelim\"), (\"st_rotp\", \"st_rotperr1\", \"st_rotperr2\", \"st_rotplim\")}\n",
        "\n",
        "  imputable_data_planet_low = [\"pl_orbpererr1\", \"pl_orbsmaxerr1\", \"pl_masseerr1\", \"pl_msinieerr1\", \"pl_orbeccenerr1\"]\n",
        "  imputable_data_planet_high = [\"pl_orbpererr2\", \"pl_orbsmaxerr2\", \"pl_masseerr2\", \"pl_msinieerr2\", \"pl_orbeccenerr2\"]\n",
        "  imputable_data_planet_max = [\"cb_flag\"]\n",
        "  planet_data_columns = imputable_data_planet_max + imputable_data_planet_low + imputable_data_planet_high\n",
        "\n",
        "  imputable_data_star = [\"st_masserr1\", \"st_masserr2\", \"st_ageerr1\", \"st_ageerr2\", \"st_rotperr1\", \"st_rotperr2\",\n",
        "                         \"glat\", \"glon\", \"sy_pmerr1\", \"sy_pmerr2\", \"sy_disterr1\", \"sy_disterr2\"]\n",
        "  imputable_data_star_max = [\"sy_snum\"]\n",
        "  other_data_star = [\"st_metratio\", \"st_meterr1\", \"st_meterr2\"]\n",
        "  star_data_columns = imputable_data_star_max + other_data_star + imputable_data_star\n",
        "\n",
        "  max_imputable_data = imputable_data_planet_max + imputable_data_star_max\n",
        "\n",
        "  data_table = pandas.read_csv(file_path, converters={\"st_metratio\":metallicity_parser}, comment='#')\n",
        "  data_table = data_table.loc[(data_table[\"hostname\"] in existing_stars) and (data_table[\"rv_flag\"] == 1) and (data_table[\"st_nrvc\"] > 0)]\n",
        "\n",
        "  model_x1_list = list()\n",
        "  model_x1_paddings = list()\n",
        "  model_y_list = list()\n",
        "\n",
        "  max_planets_number = 0\n",
        "\n",
        "  for star in existing_stars:\n",
        "    planets_table = pandas.DataFrame(columns=data_table.columns)\n",
        "\n",
        "    exoplanets = set(data_table.loc[data_table[\"hostname\"] == star, \"pl_name\"])\n",
        "    for exoplanet in exoplanets:\n",
        "      use_sources = data_table.loc[data_table[\"pl_name\"] == exoplanet]\n",
        "\n",
        "      is_non_controversial = (use_sources[\"pl_controv_flag\"] == 0)\n",
        "      if is_non_controversial.any():\n",
        "        use_sources = use_sources.loc[is_non_controversial]\n",
        "\n",
        "      is_confirmed = (use_sources[\"soltype\"] == \"Published Confirmed\")\n",
        "      if is_confirmed.any():\n",
        "        use_sources = use_sources.loc[is_confirmed]\n",
        "\n",
        "      for row in use_sources.index:\n",
        "        for (number, uncertainty_up, uncertainty_down) in triplet_data:\n",
        "          if pandas.isna(use_sources.at[row, number]):\n",
        "            use_sources.at[row, uncertainty_up] = numpy.nan\n",
        "            use_sources.at[row, uncertainty_down] = numpy.nan\n",
        "          else:\n",
        "            if pandas.isna(use_sources.at[row, uncertainty_up]):\n",
        "              use_sources.at[row, uncertainty_up] = 0\n",
        "            use_sources.at[row, uncertainty_up] += use_sources.at[row, number]\n",
        "            if pandas.isna(use_sources.at[row, uncertainty_down]):\n",
        "              use_sources.at[row, uncertainty_down] = 0\n",
        "            use_sources.at[row, uncertainty_down] += use_sources.at[row, number]\n",
        "\n",
        "        for (number, uncertainty_up, uncertainty_down, limit) in quadruplet_data:\n",
        "          if pandas.isna(use_sources.at[row, number]):\n",
        "            use_sources.at[row, uncertainty_up] = numpy.nan\n",
        "            use_sources.at[row, uncertainty_down] = numpy.nan\n",
        "          else:\n",
        "            if pandas.isna(use_sources.at[row, uncertainty_up]):\n",
        "              use_sources.at[row, uncertainty_up] = 0\n",
        "            use_sources.at[row, uncertainty_up] += use_sources.at[row, number]\n",
        "            if(use_sources.at[row, limit] == 1):\n",
        "              use_sources.at[row, uncertainty_down] = numpy.nan\n",
        "            else:\n",
        "              if pandas.isna(use_sources.at[row, uncertainty_down]):\n",
        "                use_sources.at[row, uncertainty_down] = 0\n",
        "              use_sources.at[row, uncertainty_down] += use_sources.at[row, number]\n",
        "\n",
        "      is_default_data = (use_sources[\"default_flag\"] == 1)\n",
        "      if is_default_data.any():\n",
        "        planets_table.loc[exoplanet] = use_sources.iloc[is_default_data.argmax()]\n",
        "      else:\n",
        "        planets_table.loc[exoplanet] = None\n",
        "\n",
        "      for column_label in imputable_data_planet_low:\n",
        "        if pandas.isna(planets_table.at[exoplanet, column_label]):\n",
        "          planets_table.at[exoplanet, column_label] = average_or_nan(use_sources[column_label], default=0)\n",
        "      for column_label in imputable_data_planet_high:\n",
        "        upper_bound = float('inf')\n",
        "        if(column_label == \"pl_orbeccenerr2\"):\n",
        "          upper_bound = 1\n",
        "        if pandas.isna(planets_table.at[exoplanet, column_label]):\n",
        "          planets_table.at[exoplanet, column_label] = average_or_nan(use_sources[column_label], default=upper_bound)\n",
        "      for column_label in imputable_data_star:\n",
        "        if pandas.isna(planets_table.at[exoplanet, column_label]):\n",
        "          planets_table.at[exoplanet, column_label] = average_or_nan(use_sources[column_label], default=numpy.nan)\n",
        "\n",
        "      for column_label in max_imputable_data:\n",
        "        if pandas.isna(planets_table.at[exoplanet, column_label]):\n",
        "          planets_table.at[exoplanet, column_label] = max_or_nan(use_sources[column_label])\n",
        "\n",
        "      if pandas.isna(planets_table.at[exoplanet, \"st_metratio\"]):\n",
        "        planets_table.at[exoplanet, \"st_metratio\"], data_locations = find_metallicity_standard(use_sources[\"st_metratio\"])\n",
        "        planets_table.at[exoplanet, \"st_meterr1\"] = average_or_nan(use_sources.loc[data_locations, \"st_meterr1\"], default=numpy.nan)\n",
        "        planets_table.at[exoplanet, \"st_meterr2\"] = average_or_nan(use_sources.loc[data_locations, \"st_meterr2\"], default=numpy.nan)\n",
        "      else:\n",
        "        same_unit = (use_sources[\"st_metratio\"] == planets_table.at[exoplanet, \"st_metratio\"])\n",
        "        if pandas.isna(planets_table.at[exoplanet, \"st_meterr1\"]):\n",
        "          planets_table.at[exoplanet, \"st_meterr1\"] = average_or_nan(use_sources.loc[same_unit, \"st_meterr1\"], default=numpy.nan)\n",
        "        if pandas.isna(planets_table.at[exoplanet, \"st_meterr2\"]):\n",
        "          planets_table.at[exoplanet, \"st_meterr2\"] = average_or_nan(use_sources.loc[same_unit, \"st_meterr2\"], default=numpy.nan)\n",
        "\n",
        "    planets_data = (planets_table[planet_data_columns]).sort_values(planet_data_columns)\n",
        "    model_y_list.append([(planets_data.loc[row_name]).to_numpy(dtype=numpy.double, copy=True) for row_name in planets_table.index])\n",
        "    max_planets_number = max(max_planets_number, len(model_y_list[-1]))\n",
        "\n",
        "    star_data = dict.fromkeys(star_data_columns, numpy.nan)\n",
        "    for column_label in imputable_data_star:\n",
        "      star_data[column_label] = average_or_nan(planets_table[column_label], default=numpy.nan)\n",
        "    for column_label in imputable_data_star_max:\n",
        "      star_data[column_label] = max_or_nan(planets_table[column_label])\n",
        "    star_data[\"st_metratio\"], data_locations = find_metallicity_standard(planets_table[\"st_metratio\"])\n",
        "    star_data[\"st_meterr1\"] = average_or_nan(planets_table.loc[data_locations, \"st_meterr1\"], default=numpy.nan)\n",
        "    star_data[\"st_meterr2\"] = average_or_nan(planets_table.loc[data_locations, \"st_meterr2\"], default=numpy.nan)\n",
        "\n",
        "    star_data_list = list()\n",
        "    padding_list = (available_series[star]).copy()\n",
        "    for encoding_position, column_name in enumerate(star_data_columns):\n",
        "      encoding_vector = numpy.zeros(len(star_data_columns), dtype=numpy.double)\n",
        "      if not pandas.isna(star_data[column_name]):\n",
        "        encoding_vector[encoding_position] = star_data[column_name]\n",
        "        padding_list.append(False)\n",
        "      else:\n",
        "        padding_list.append(True)\n",
        "      star_data_list.append(encoding_vector)\n",
        "    model_x1_list.append(star_data_list)\n",
        "    model_x1_paddings.append(padding_list)\n",
        "\n",
        "  for y_entry in model_y_list:\n",
        "    for padding in range(max_planets_number-len(y_entry)):\n",
        "      y_entry.append(numpy.zeros(len(planet_data_columns), dtype=numpy.double))\n",
        "\n",
        "  model_x1 = torch.from_numpy(numpy.asarray(model_x1_list, dtype=numpy.double))\n",
        "  model_x1_mask = torch.from_numpy(numpy.asarray(model_x1_paddings, dtype=numpy.bool_))\n",
        "  model_y = torch.from_numpy(numpy.asarray(model_y_list, dtype=numpy.double))\n",
        "\n",
        "  return model_x1, model_x1_mask, model_y"
      ]
    }
  ]
}