{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "main.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas\n",
        "import math\n",
        "import itertools\n",
        "import numpy\n",
        "import torch\n",
        "import matplotlib\n",
        "\n",
        "def parse_folder(folder_name, suffix):\n",
        "  filenames = os.listdir(folder_name)\n",
        "  full_filenames = [os.path.join(folder_name, filename) for filename in filenames if filename.endswith(suffix)]\n",
        "  print(\"Found\", len(full_filenames), \"files.\\n\")\n",
        "\n",
        "  max_series_length = 0\n",
        "  max_num_series = 0\n",
        "\n",
        "  data_dict = dict()\n",
        "\n",
        "  for file in full_filenames:\n",
        "    whole_file = open(file, \"r\")\n",
        "    star_id = whole_file.readline().strip()\n",
        "    while((not (star_id.startswith(\"\\\\STAR_ID\"))) or (star_id.startswith(\"\\\\STAR_ID_DEFINED\"))):\n",
        "      star_id = whole_file.readline().strip()\n",
        "      if not star_id:\n",
        "        print(\"Star ID not found for file\", file)\n",
        "        break\n",
        "    \n",
        "    line_contents = star_id.split(\"=\", 1)\n",
        "    star_name = (line_contents[-1]).strip().replace(\"\\'\", \"\").replace(\"\\\"\", \"\")\n",
        "\n",
        "    time_series = pandas.read_table(file, comment=\"\\\\\", header=None, delim_whitespace=True, skipinitialspace=True)\n",
        "\n",
        "    time_series = time_series.loc[(pandas.isna(time_series[0]) != True) & (pandas.isna(time_series[1]) != True)]\n",
        "    for row_label in time_series.index:\n",
        "      if(pandas.isna(time_series.at[row_label, 2])):\n",
        "        time_series.at[row_label, 2] = 0\n",
        "    \n",
        "    max_series_length = max(max_series_length, len(time_series))\n",
        "    series_data = [(time_series[i]).tolist() for i in range(3)]\n",
        "\n",
        "    if star_name in data_dict:\n",
        "      (data_dict[star_name]).append(series_data)\n",
        "    else:\n",
        "      data_dict[star_name] = [series_data]\n",
        "    max_num_series = max(max_num_series, len(data_dict[star_name]))\n",
        "\n",
        "  stars_list = list()\n",
        "  series_masks = dict()\n",
        "  batched_series = [list() for batch in range(max_num_series)]\n",
        "\n",
        "  for star in data_dict:\n",
        "    stars_list.append(star)\n",
        "    series_masks[star] = ([False]*len(data_dict[star]))+([True]*(max_num_series-len(data_dict[star])))\n",
        "\n",
        "    for data_series in data_dict[star]:\n",
        "      for data_axis in range(3):\n",
        "        extend_factor = math.ceil(max_series_length/len(data_series[data_axis]))\n",
        "        data_series[data_axis] = ((data_series[data_axis])*extend_factor)[:max_series_length]\n",
        "        \n",
        "    for data_series, into_batch in zip(itertools.cycle(data_dict[star]), range(max_num_series)):\n",
        "      batched_series[into_batch].append(numpy.asarray(data_series, dtype=numpy.double))\n",
        "\n",
        "  batches_list = [torch.from_numpy(numpy.asarray(batch, dtype=numpy.double)) for batch in batched_series]\n",
        "    \n",
        "  print(\"Longest data series:\", max_series_length)\n",
        "  print(\"The most number of data series for one star:\", max_num_series)\n",
        "  return stars_list, series_masks, batches_list"
      ],
      "metadata": {
        "id": "i48qw6EHQhOU"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metallicity_table = {\"[m/H]\":1, \"[M/H]\":1, \"[Fe/H]\":2}\n",
        "def metallicity_parser(input_string):\n",
        "  return metallicity_table.get(input_string, numpy.nan)\n",
        "\n",
        "def average_or_nan(series, default=numpy.nan):\n",
        "  if (pandas.isna(series) != True).any():\n",
        "    return series.mean()\n",
        "  else:\n",
        "    return default\n",
        "\n",
        "def max_or_nan(series):\n",
        "  if (pandas.isna(series) != True).any():\n",
        "    return series.max()\n",
        "  else:\n",
        "    return numpy.nan\n",
        "\n",
        "def find_metallicity_standard(series):\n",
        "  uses_M_H = (series == 1)\n",
        "  if uses_M_H.any():\n",
        "    return 1, uses_M_H\n",
        "  else:\n",
        "    uses_Fe_H = (series == 2)\n",
        "    if uses_Fe_H.any():\n",
        "      return 2, uses_Fe_H\n",
        "    else:\n",
        "      return numpy.nan, uses_Fe_H\n",
        "\n",
        "def parse_table(file_path, existing_stars, available_series):\n",
        "  \"\"\"\n",
        "  Inputs:\n",
        "    file_path: String.\n",
        "    existing_stars: Set. Contains strings.\n",
        "  Outputs:\n",
        "    model_x1: 3D PyTorch tensor.\n",
        "    model_x1_mask: 2D PyTorch tensor.\n",
        "    model_y: 3D PyTorch tensor.\n",
        "  \"\"\"\n",
        "\n",
        "  triplet_data = {(\"sy_pm\", \"sy_pmerr1\", \"sy_pmerr2\"), (\"sy_dist\", \"sy_disterr1\", \"sy_disterr2\")}\n",
        "  quadruplet_data = {(\"st_mass\", \"st_masserr1\", \"st_masserr2\", \"st_masslim\"), (\"st_met\", \"st_meterr1\", \"st_meterr2\", \"st_metlim\"),\n",
        "                     (\"st_age\", \"st_ageerr1\", \"st_ageerr2\", \"st_agelim\"), (\"st_rotp\", \"st_rotperr1\", \"st_rotperr2\", \"st_rotplim\")}\n",
        "\n",
        "  imputable_data_planet_low = [\"pl_orbpererr1\", \"pl_orbsmaxerr1\", \"pl_masseerr1\", \"pl_msinieerr1\", \"pl_orbeccenerr1\"]\n",
        "  imputable_data_planet_high = [\"pl_orbpererr2\", \"pl_orbsmaxerr2\", \"pl_masseerr2\", \"pl_msinieerr2\", \"pl_orbeccenerr2\"]\n",
        "  imputable_data_planet_max = [\"cb_flag\"]\n",
        "  planet_data_columns = imputable_data_planet_max + imputable_data_planet_low + imputable_data_planet_high\n",
        "\n",
        "  imputable_data_star = [\"st_masserr1\", \"st_masserr2\", \"st_ageerr1\", \"st_ageerr2\", \"st_rotperr1\", \"st_rotperr2\",\n",
        "                         \"glat\", \"glon\", \"sy_pmerr1\", \"sy_pmerr2\", \"sy_disterr1\", \"sy_disterr2\"]\n",
        "  imputable_data_star_max = [\"sy_snum\"]\n",
        "  other_data_star = [\"st_metratio\", \"st_meterr1\", \"st_meterr2\"]\n",
        "  star_data_columns = imputable_data_star_max + other_data_star + imputable_data_star\n",
        "\n",
        "  max_imputable_data = imputable_data_planet_max + imputable_data_star_max\n",
        "\n",
        "  data_table = pandas.read_csv(file_path, converters={\"st_metratio\":metallicity_parser}, comment='#')\n",
        "  data_table = data_table.loc[(data_table[\"hostname\"].isin(existing_stars)) & (data_table[\"rv_flag\"] == 1) & (data_table[\"st_nrvc\"] > 0)]\n",
        "\n",
        "  model_x1_list = list()\n",
        "  model_x1_paddings = list()\n",
        "  model_y_list = list()\n",
        "\n",
        "  max_planets_number = 0\n",
        "  model_size = max(len(star_data_columns), len(planet_data_columns))\n",
        "  output_pad = [0]*(len(star_data_columns)-len(planet_data_columns))\n",
        "\n",
        "  for star in existing_stars:\n",
        "    planets_table = pandas.DataFrame(columns=data_table.columns)\n",
        "\n",
        "    exoplanets = set(data_table.loc[data_table[\"hostname\"] == star, \"pl_name\"])\n",
        "    for exoplanet in exoplanets:\n",
        "      use_sources = data_table.loc[data_table[\"pl_name\"] == exoplanet]\n",
        "\n",
        "      is_non_controversial = (use_sources[\"pl_controv_flag\"] == 0)\n",
        "      if is_non_controversial.any():\n",
        "        use_sources = use_sources.loc[is_non_controversial]\n",
        "\n",
        "      is_confirmed = (use_sources[\"soltype\"] == \"Published Confirmed\")\n",
        "      if is_confirmed.any():\n",
        "        use_sources = use_sources.loc[is_confirmed]\n",
        "\n",
        "      for row in use_sources.index:\n",
        "        for (number, uncertainty_up, uncertainty_down) in triplet_data:\n",
        "          if pandas.isna(use_sources.at[row, number]):\n",
        "            use_sources.at[row, uncertainty_up] = numpy.nan\n",
        "            use_sources.at[row, uncertainty_down] = numpy.nan\n",
        "          else:\n",
        "            if pandas.isna(use_sources.at[row, uncertainty_up]):\n",
        "              use_sources.at[row, uncertainty_up] = 0\n",
        "            use_sources.at[row, uncertainty_up] += use_sources.at[row, number]\n",
        "            if pandas.isna(use_sources.at[row, uncertainty_down]):\n",
        "              use_sources.at[row, uncertainty_down] = 0\n",
        "            use_sources.at[row, uncertainty_down] += use_sources.at[row, number]\n",
        "\n",
        "        for (number, uncertainty_up, uncertainty_down, limit) in quadruplet_data:\n",
        "          if pandas.isna(use_sources.at[row, number]):\n",
        "            use_sources.at[row, uncertainty_up] = numpy.nan\n",
        "            use_sources.at[row, uncertainty_down] = numpy.nan\n",
        "          else:\n",
        "            if pandas.isna(use_sources.at[row, uncertainty_up]):\n",
        "              use_sources.at[row, uncertainty_up] = 0\n",
        "            use_sources.at[row, uncertainty_up] += use_sources.at[row, number]\n",
        "            if(use_sources.at[row, limit] == 1):\n",
        "              use_sources.at[row, uncertainty_down] = numpy.nan\n",
        "            else:\n",
        "              if pandas.isna(use_sources.at[row, uncertainty_down]):\n",
        "                use_sources.at[row, uncertainty_down] = 0\n",
        "              use_sources.at[row, uncertainty_down] += use_sources.at[row, number]\n",
        "\n",
        "      is_default_data = (use_sources[\"default_flag\"] == 1)\n",
        "      if is_default_data.any():\n",
        "        planets_table.loc[exoplanet] = use_sources.iloc[is_default_data.argmax()]\n",
        "      else:\n",
        "        planets_table.loc[exoplanet] = None\n",
        "\n",
        "      for column_label in imputable_data_planet_low:\n",
        "        if pandas.isna(planets_table.at[exoplanet, column_label]):\n",
        "          planets_table.at[exoplanet, column_label] = average_or_nan(use_sources[column_label], default=0)\n",
        "      for column_label in imputable_data_planet_high:\n",
        "        upper_bound = float('inf')\n",
        "        if(column_label == \"pl_orbeccenerr2\"):\n",
        "          upper_bound = 1\n",
        "        if pandas.isna(planets_table.at[exoplanet, column_label]):\n",
        "          planets_table.at[exoplanet, column_label] = average_or_nan(use_sources[column_label], default=upper_bound)\n",
        "      for column_label in imputable_data_star:\n",
        "        if pandas.isna(planets_table.at[exoplanet, column_label]):\n",
        "          planets_table.at[exoplanet, column_label] = average_or_nan(use_sources[column_label], default=numpy.nan)\n",
        "\n",
        "      for column_label in max_imputable_data:\n",
        "        if pandas.isna(planets_table.at[exoplanet, column_label]):\n",
        "          planets_table.at[exoplanet, column_label] = max_or_nan(use_sources[column_label])\n",
        "\n",
        "      if pandas.isna(planets_table.at[exoplanet, \"st_metratio\"]):\n",
        "        planets_table.at[exoplanet, \"st_metratio\"], data_locations = find_metallicity_standard(use_sources[\"st_metratio\"])\n",
        "        planets_table.at[exoplanet, \"st_meterr1\"] = average_or_nan(use_sources.loc[data_locations, \"st_meterr1\"], default=numpy.nan)\n",
        "        planets_table.at[exoplanet, \"st_meterr2\"] = average_or_nan(use_sources.loc[data_locations, \"st_meterr2\"], default=numpy.nan)\n",
        "      else:\n",
        "        same_unit = (use_sources[\"st_metratio\"] == planets_table.at[exoplanet, \"st_metratio\"])\n",
        "        if pandas.isna(planets_table.at[exoplanet, \"st_meterr1\"]):\n",
        "          planets_table.at[exoplanet, \"st_meterr1\"] = average_or_nan(use_sources.loc[same_unit, \"st_meterr1\"], default=numpy.nan)\n",
        "        if pandas.isna(planets_table.at[exoplanet, \"st_meterr2\"]):\n",
        "          planets_table.at[exoplanet, \"st_meterr2\"] = average_or_nan(use_sources.loc[same_unit, \"st_meterr2\"], default=numpy.nan)\n",
        "\n",
        "    planets_data = (planets_table[planet_data_columns]).sort_values(planet_data_columns)\n",
        "    model_y_list.append([numpy.asarray(((planets_data.loc[row_name]).tolist())+output_pad, dtype=numpy.double) for row_name in planets_table.index])\n",
        "    max_planets_number = max(max_planets_number, len(model_y_list[-1]))\n",
        "\n",
        "    star_data = dict.fromkeys(star_data_columns, numpy.nan)\n",
        "    for column_label in imputable_data_star:\n",
        "      star_data[column_label] = average_or_nan(planets_table[column_label], default=numpy.nan)\n",
        "    for column_label in imputable_data_star_max:\n",
        "      star_data[column_label] = max_or_nan(planets_table[column_label])\n",
        "    star_data[\"st_metratio\"], data_locations = find_metallicity_standard(planets_table[\"st_metratio\"])\n",
        "    star_data[\"st_meterr1\"] = average_or_nan(planets_table.loc[data_locations, \"st_meterr1\"], default=numpy.nan)\n",
        "    star_data[\"st_meterr2\"] = average_or_nan(planets_table.loc[data_locations, \"st_meterr2\"], default=numpy.nan)\n",
        "\n",
        "    star_data_list = list()\n",
        "    padding_list = (available_series[star]).copy()\n",
        "    for encoding_position, column_name in enumerate(star_data_columns):\n",
        "      encoding_vector = numpy.zeros(model_size, dtype=numpy.double)\n",
        "      if not pandas.isna(star_data[column_name]):\n",
        "        encoding_vector[encoding_position] = star_data[column_name]\n",
        "        padding_list.append(False)\n",
        "      else:\n",
        "        padding_list.append(True)\n",
        "      star_data_list.append(encoding_vector)\n",
        "    model_x1_list.append(star_data_list)\n",
        "    model_x1_paddings.append(padding_list)\n",
        "\n",
        "  for y_entry in model_y_list:\n",
        "    for padding in range(max_planets_number-len(y_entry)):\n",
        "      y_entry.append(numpy.zeros(model_size, dtype=numpy.double))\n",
        "\n",
        "  model_x1 = torch.from_numpy(numpy.asarray(model_x1_list, dtype=numpy.double))\n",
        "  model_x1_mask = torch.from_numpy(numpy.asarray(model_x1_paddings, dtype=numpy.bool_))\n",
        "  model_y = torch.from_numpy(numpy.asarray(model_y_list, dtype=numpy.double))\n",
        "\n",
        "  print(\"The most number of planets for one star:\", max_planets_number)\n",
        "  return model_x1, model_x1_mask, model_y"
      ],
      "metadata": {
        "id": "igRoTxlLQi2b"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_validation_split(main_data, data_mask, series_batch, targets):\n",
        "  length = (main_data.shape)[0]\n",
        "  split = int(length*0.8)\n",
        "  train_batch = [batch[:split] for batch in series_batch]\n",
        "  validation_batch = [batch[split:] for batch in series_batch]\n",
        "  return main_data[:split], data_mask[:split], train_batch, targets[:split], main_data[split:], data_mask[split:], validation_batch, targets[split:]"
      ],
      "metadata": {
        "id": "-W9QEaQgSO6z"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ii0yGn_x222z"
      },
      "outputs": [],
      "source": [
        "class PlanetDetector(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super(PlanetDetector, self).__init__()\n",
        "    self.conv_layers = torch.nn.Sequential(torch.nn.Conv1d(3, 3, 6, stride=2, dtype=torch.double), torch.nn.ReLU(),\n",
        "                                           torch.nn.Conv1d(3, 2, 6, stride=2, dtype=torch.double), torch.nn.ReLU(),\n",
        "                                           torch.nn.Conv1d(2, 2, 6, stride=2, dtype=torch.double), torch.nn.ReLU(),\n",
        "                                           torch.nn.Conv1d(2, 1, 6, stride=2, dtype=torch.double), torch.nn.ReLU(),\n",
        "                                           torch.nn.Conv1d(1, 1, 6, stride=2, dtype=torch.double), torch.nn.ReLU(),\n",
        "                                           torch.nn.Linear(17, 16, dtype=torch.double), torch.nn.ReLU())\n",
        "    self.linear_layers = torch.nn.Sequential(torch.nn.Linear(16, 16, dtype=torch.double),\n",
        "                                             torch.nn.Linear(16, 16, dtype=torch.double),\n",
        "                                             torch.nn.Linear(16, 16, dtype=torch.double),\n",
        "                                             torch.nn.Linear(16, 16, dtype=torch.double),\n",
        "                                             torch.nn.Linear(16, 16, dtype=torch.double))\n",
        "    #self.transformer = torch.nn.Transformer(d_model=16, batch_first=True, dtype=torch.double)\n",
        "\n",
        "  def forward(self, x1, x1_mask, x2s, y):\n",
        "    after_conv = [self.conv_layers(batch) for batch in x2s]\n",
        "    full_data = torch.cat((*after_conv, x1), dim=1)\n",
        "    return self.linear_layers(full_data) #self.transformer(full_data, y, src_key_padding_mask=x1_mask)\n",
        "\n",
        "model = PlanetDetector()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0, amsgrad=True)\n",
        "\n",
        "loss_gate = torch.nn.ReLU()\n",
        "least_square = torch.nn.MSELoss(reduction=\"mean\")\n",
        "def loss(x1, x1_mask, x2s, y):\n",
        "  outputs = (model(x1, x1_mask, x2s, y))[:, 0:6, :]\n",
        "  target = torch.zeros_like(y, dtype=torch.double)\n",
        "\n",
        "  mask = torch.logical_not(torch.isnan(y))\n",
        "\n",
        "  exact_loss = least_square(torch.masked_select(outputs[:, :, 0], mask[:, :, 0]), torch.masked_select(y[:, :, 0], mask[:, :, 0]))\n",
        "  low_loss = least_square(torch.masked_select(loss_gate((y[:, :, 1:5])-(outputs[:, :, 1:5])), mask[:, :, 1:5]), torch.masked_select(target[:, :, 1:5], mask[:, :, 1:5]))\n",
        "  high_loss = least_square(torch.masked_select(loss_gate((outputs[:, :, 6:10])-(y[:, :, 6:10])), mask[:, :, 6:10]), torch.masked_select(target[:, :, 6:10], mask[:, :, 6:10]))\n",
        "\n",
        "  return exact_loss+low_loss+high_loss"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stars_list, series_masks, batches_list = parse_folder(\"drive/MyDrive/ECE324/data\", \".tbl\")\n",
        "model_x1, model_x1_mask, model_y = parse_table(\"drive/MyDrive/ECE324/data/PS_2022.03.11_13.14.43.csv\", stars_list, series_masks)\n",
        "X_train, M_train, B_train, Y_train, X_validate, M_validate, B_validate, Y_validate = train_validation_split(model_x1, model_x1_mask, batches_list, model_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ebqa6oBsXtKc",
        "outputId": "c5192fe9-6b72-45cc-b6ac-683b6aa97460"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1071 files.\n",
            "\n",
            "Longest data series: 678\n",
            "The most number of data series for one star: 11\n",
            "The most number of planets for one star: 6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(stars_list))"
      ],
      "metadata": {
        "id": "cWrXYo9aXlN3",
        "outputId": "936ad652-6b2c-4c72-859c-ce5e87a1a3f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "552\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def auto_stop_train(loss_function, optimizer, X_train, M_train, B_train, Y_train, X_validate, M_validate, B_validate, Y_validate):\n",
        "  train_loss_record = list()\n",
        "  validation_loss_record = list()\n",
        "  best_validation_loss = numpy.inf\n",
        "  epochs_no_improvement = 0\n",
        "\n",
        "  for epoch in range(25):\n",
        "    if not(epochs_no_improvement < 20):\n",
        "      break\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    train_loss = loss_function(X_train, M_train, B_train, Y_train)\n",
        "    train_loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    with torch.no_grad():\n",
        "      validation_loss = loss_function(X_validate, M_validate, B_validate, Y_validate)\n",
        "      validation_loss_value = numpy.half(validation_loss.item())\n",
        "      if((validation_loss_value >= best_validation_loss) or (pandas.isna(validation_loss_value))):\n",
        "        epochs_no_improvement += 1\n",
        "      else:\n",
        "        epochs_no_improvement = 0\n",
        "      best_validation_loss = min(best_validation_loss, validation_loss_value)\n",
        "\n",
        "      train_loss_record.append(numpy.half(train_loss.item()))\n",
        "      validation_loss_record.append(validation_loss_value)\n",
        "\n",
        "  optimizer.zero_grad(set_to_none=True)\n",
        "  print(\"Total epochs:\", len(train_loss_record))\n",
        "  return train_loss_record, validation_loss_record\n",
        "\n",
        "def loss_plot(train_loss, validation_loss, title_text=\"Training and Validation Loss\", label_x=\"Epoch\"):\n",
        "  matplotlib.pyplot.title(title_text)\n",
        "  matplotlib.pyplot.plot(train_loss, label=\"Training\")\n",
        "  matplotlib.pyplot.plot(validation_loss, label=\"Validation\")\n",
        "  matplotlib.pyplot.xlabel(label_x)\n",
        "  matplotlib.pyplot.ylabel(\"Loss\")\n",
        "  matplotlib.pyplot.legend(loc=\"best\")\n",
        "  matplotlib.pyplot.show()\n",
        "  print(\"Final validation loss: \", validation_loss[-1])\n",
        "\n",
        "train_loss_record_1, validation_loss_record_1 = auto_stop_train(loss, optimizer, X_train, M_train, B_train, Y_train, X_validate, M_validate, B_validate, Y_validate)\n",
        "loss_plot(train_loss_record_1, validation_loss_record_1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "id": "DnRe7zGnRBoM",
        "outputId": "2965afcf-4c58-404d-fba5-a06665d7cbdb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total epochs: 25\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final validation loss:  1007.5\n"
          ]
        }
      ]
    }
  ]
}